{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DataParallel\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.ops import focal_loss\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt      \n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms   \n",
    "from torch.optim.lr_scheduler import StepLR   \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/l/users/mugariya.farooq/miccai/frames'\n",
    "train_path = 'train_data.csv'\n",
    "test_path = 'test_data.csv'\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "#batch_size = 4\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cholec(Dataset):\n",
    "    def __init__(self, data_dir, label_path, transforms= None):\n",
    "        self.data_dir = data_dir\n",
    "        self.label_path = label_path\n",
    "        self.transforms = transforms\n",
    "        self.df = pd.read_csv(label_path, index_col=0)\n",
    "    def __len__(self):\n",
    "        return  self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        img_name = row['video_name'] + '_' + str(int(int(row['Frame']) / 25) + 1).zfill(6) + '.png'\n",
    "        img_path = self.data_dir + '/' + row['video_name'] + '/' + img_name\n",
    "        #img_data = np.array(Image.open(self.img_dir + '/' + img_name).convert('RGB'), dtype='float32')\n",
    "        img_data = Image.open(img_path)\n",
    "        if self.transforms:\n",
    "            img_data = self.transforms(img_data)\n",
    "            \n",
    "        label = row[1:7].values\n",
    "        return img_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds= cholec( data_dir= data_path, label_path=train_path, transforms= None)\n",
    "test_ds= cholec( data_dir= data_path, label_path=test_path, transforms= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_t = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "# dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dl_test = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2fzg82x1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">generous-sunset-1</strong>: <a href=\"https://wandb.ai/mughaira/stl_cholec/runs/2fzg82x1\" target=\"_blank\">https://wandb.ai/mughaira/stl_cholec/runs/2fzg82x1</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220828_113728-2fzg82x1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2fzg82x1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/l/users/mugariya.farooq/miccai/wandb/run-20220828_113910-63aydx8j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mughaira/stl_cholec/runs/63aydx8j\" target=\"_blank\">northern-pond-2</a></strong> to <a href=\"https://wandb.ai/mughaira/stl_cholec\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_path = 'checkpoints_cholec_'\n",
    "load_weights = False\n",
    "weights_pth = 'path/to/checkpoint.pth' # !!!!! WEIGHTS MUST BE WRAPPED IN DATAPARALLEL, OTHERWISE CRASHES !!!!!\n",
    "wandb_project_name = 'stl_' + 'cholec'\n",
    "\n",
    "\n",
    "# WANDB\n",
    "wandb.init(project=wandb_project_name)\n",
    "wandb.config = {\n",
    "        'learning_rate': 0.0001,\n",
    "        'epochs': 5,\n",
    "        'batch_size': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "print('=' * 10, 'preparing the model', '=' * 10)\n",
    "\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "n_in_f = model.fc.in_features\n",
    "model.fc = nn.Linear(n_in_f, 6)\n",
    "model = DataParallel(module=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = focal_loss.sigmoid_focal_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "\n",
    "# TRAIN + VALID CYCLE\n",
    "for epoch in range(5):\n",
    "    print('epoch', epoch, 'started')\n",
    "    \n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    for i, (data_, target_) in enumerate(dl_t):\n",
    "        data_, target_ = data_, target_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_)\n",
    "        loss = criterion(outputs, target_, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print('loss:', loss.data)\n",
    "            wandb.log({'loss':loss})\n",
    "\n",
    "    model.eval()\n",
    "    preds = np.empty((0,6), float)\n",
    "    for i, (data_, target_) in enumerate(dl_test):\n",
    "        outputs = model(data_.to(device))\n",
    "        outputs = torch.sigmoid(outputs).detach().cpu().numpy()\n",
    "        preds = np.append(preds, outputs, axis=0)\n",
    "        if preds.shape[0] % 100 == 0:\n",
    "            print('eval iteration', preds.shape[0])\n",
    "    target = test_ds.df[test_ds.df.columns[1:7].values\n",
    "    f1 = f1_score(target, preds > 0.5, average='macro')\n",
    "    auc = roc_auc_score(target, preds, average='macro')\n",
    "    print(f1, auc)\n",
    "    wandb.log({'val_f1_score':f1})\n",
    "    wandb.log({'val_auc':auc})\n",
    "        \n",
    "    print('epoch', epoch, 'done')\n",
    "    torch.save(model.state_dict(), checkpoint_path + '/' +'_epoch' + str(epoch) + '_' + '.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('miccai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f6cfd28a4e6a9bb65512d55507f896ccd85344506a5e0f58c152825f029472b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
